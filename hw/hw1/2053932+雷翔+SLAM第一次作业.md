# HW1

2053932 雷翔

## Q1：

根据所给图像完成：输出图像的高度、宽度、通道数，并将图像旋转（学号后两位）°后显示

原始图像：

![image.png](https://lei-1306809548.cos.ap-shanghai.myqcloud.com/Obsidianimage.png)

```bash
(base) PS C:\Users\27180> & D:/anaconda/python.exe d:/third-year/SLAM/hw1/hw1.py
Image width:  268
Image height:  382
Number of channels:  3
```

逆时针旋转 32°：

![rotated_image1.png](https://lei-1306809548.cos.ap-shanghai.myqcloud.com/Obsidianrotated_image1.png)

顺时针旋转 32°：

![rotated_image2.png](https://lei-1306809548.cos.ap-shanghai.myqcloud.com/Obsidianrotated_image2.png)

```python
"""
@File    :   hw1.py
@Time    :   2024/04/15 20:21:21
@Author  :   Xiang Lei 
@Version :   1.0
@Desc    :   None
"""

import cv2
import numpy as np


def rotate_image(image_path, angle):
    image = cv2.imread(image_path)
    w, h, c = image.shape
    M = cv2.getRotationMatrix2D((h / 2, w / 2), angle, 1)
    rotated_image = cv2.warpAffine(image, M, (h, w))
    return rotated_image


image_path = "D:/third-year/SLAM/hw1/image.png"

image = cv2.imread(image_path)

h, w, c = image.shape

print("Image width: ", w)
print("Image height: ", h)
print("Number of channels: ", c)

# 学号：2053932 -> 将图片顺（逆）旋转 32 度
rotated_image1 = rotate_image(image_path, 32)
rotated_image2 = rotate_image(image_path, -32)

cv2.imwrite("rotated_image1.png", rotated_image1)
cv2.imwrite("rotated_image2.png", rotated_image2)
```

## Q2：

输出TUM数据集中的前798*百分之（学号%30+60）个数据对应的点云图（数据集：rgbd_dataset_freiburg1_xyz）

撰写实验文档，具体包含实验的关键代码截图以及效果图，对内容2重点描述对位姿文件以及图像文件之间对应关系的处理（附此段代码截图），以及点云效果图

### Step1：处理 TUM 数据集

匹配规则：通过对第二个文件的时间戳加上一个偏移量（模拟两个传感器之间的时间延迟），只有当两个时间戳（第一个文件的原始时间戳和调整后的第二个文件的时间戳）之间的差异小于最大差异限制`max_difference`时，才考虑它们为匹配项。

执行以下命令，根据 `rgb.txt` 和 `depth.txt` 两个文件夹的采集时间进行配对，将结果保存在 `associate.txt` 文件夹中：

```bash
python associate.py rgb.txt depth.txt > associate.txt
```

接着，合并 `groundtruth.txt` 的内容：

```bash
python associate.py rgb.txt groundtruth.txt > associations.txt
```

### Step2：处理图像和位姿数据

`associations.txt` 数据示例：

```
1305031102.175304 rgb/1305031102.175304.png 1305031102.160407 depth/1305031102.160407.png 1305031102.175800 1.3405 0.6266 1.6575 0.6574 0.6126 -0.2949 -0.3248
1305031102.211214 rgb/1305031102.211214.png 1305031102.226738 depth/1305031102.226738.png 1305031102.215900 1.3303 0.6256 1.6464 0.6579 0.6161 -0.2932 -0.3189
1305031102.275326 rgb/1305031102.275326.png 1305031102.262886 depth/1305031102.262886.png 1305031102.275800 1.3160 0.6254 1.6302 0.6609 0.6199 -0.2893 -0.3086
```

第一项和第二项为 rgb 图像的时间戳和路径；第三项和第四项为 depth 图像的时间戳和路径；后面为 位姿时间戳以及 7 个参数。

下面是读取位姿文件的核心代码：

```python
// 前798*百分之（学号%30+60）个数据
// 798 * 0.72 = 574.56
for (int i = 0; i < 575; i++) {
    // boost::format fmt("./%s/%d.%s"); //图像文件格式
    // colorImgs.push_back(cv::imread((fmt % "color" % (i + 1) % "png").str()));
    // depthImgs.push_back(cv::imread((fmt % "depth" % (i + 1) % "pgm").str(), -1)); // 使用-1读取原始图像

    string data[12];
    for (int j = 0; j < 12; j++) {
        fin >> data[j];
    }
    // cout << "./" + data[1] << endl;
    // cout << "./" + data[3] << endl;
    colorImgs.push_back(cv::imread("./" + data[1]));
    depthImgs.push_back(cv::imread("./" + data[3], -1));  // 使用-1读取原始图像

    double double_data[7];
    for(int j=5; j<12; j++)
    {
        double_data[j-5]=stod(data[j]);
    }
    Sophus::SE3d pose(Eigen::Quaterniond(double_data[6], double_data[3], double_data[4], double_data[5]),  
                      Eigen::Vector3d(double_data[0], double_data[1], double_data[2])); // 多添加了五列
    poses.push_back(pose);
}
```

具体思路：通过 for 循环遍历前 575 行数据，读取其中每行数据所对应的图片位置和位姿情况。

### Step3：生成点云图

利用读取到的图像和位姿数据生成三维点云，具体来说，将每个像素点都转换成三维空间中的点，通过位姿数据将点坐标由相机坐标系转换到全局坐标系。

然后编译 `joinMap.cpp` 文件所在项目，执行得到如下图点云图结果：

![608ac3dd1ed6c69f3ed2831dc7a1e0e.jpg](https://lei-1306809548.cos.ap-shanghai.myqcloud.com/Obsidian608ac3dd1ed6c69f3ed2831dc7a1e0e.jpg)